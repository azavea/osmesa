{"paragraphs":[{"text":"import geotrellis.proj4._\nimport geotrellis.spark._\nimport geotrellis.spark.io._\nimport geotrellis.spark.io.file._\nimport geotrellis.spark.io.index.ZCurveKeyIndexMethod\nimport geotrellis.spark.io.s3.{S3AttributeStore, S3LayerWriter}\nimport geotrellis.spark.tiling._\nimport geotrellis.vectortile.VectorTile\nimport org.apache.log4j.{Level, Logger}\nimport org.apache.spark._\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.sql._\nimport vectorpipe._\nimport vectorpipe.util.LayerMetadata\nimport cats.implicits._\nimport com.monovore.decline._\n","dateUpdated":"2017-09-16T01:39:50+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport geotrellis.proj4._\n\nimport geotrellis.spark._\n\nimport geotrellis.spark.io._\n\nimport geotrellis.spark.io.file._\n\nimport geotrellis.spark.io.index.ZCurveKeyIndexMethod\n\nimport geotrellis.spark.io.s3.{S3AttributeStore, S3LayerWriter}\n\nimport geotrellis.spark.tiling._\n\nimport geotrellis.vectortile.VectorTile\n\nimport org.apache.log4j.{Level, Logger}\n\nimport org.apache.spark._\n\nimport org.apache.spark.rdd.RDD\n\nimport org.apache.spark.sql._\n\nimport vectorpipe._\n\nimport vectorpipe.util.LayerMetadata\n\nimport cats.implicits._\n\nimport com.monovore.decline._\n"}]},"apps":[],"jobName":"paragraph_1505515394776_1344932248","id":"20170912-192002_1003937889","dateCreated":"2017-09-15T22:43:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1282","user":"anonymous","dateFinished":"2017-09-16T01:40:22+0000","dateStarted":"2017-09-16T01:39:50+0000"},{"text":"      /* Settings compatible for both local and EMR execution */\n      val conf = new SparkConf()\n        .setIfMissing(\"spark.master\", \"local[*]\")\n        .setAppName(\"vp-orc-io\")\n\n      implicit val ss: SparkSession = SparkSession.builder\n        .config(conf)\n        .enableHiveSupport\n        .getOrCreate\n","dateUpdated":"2017-09-16T01:43:25+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nconf: org.apache.spark.SparkConf = org.apache.spark.SparkConf@5af98b6e\n\nss: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@2e295fd4\n"}]},"apps":[],"jobName":"paragraph_1505515394782_1344162750","id":"20170912-192013_1465160975","dateCreated":"2017-09-15T22:43:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1283","user":"anonymous","dateFinished":"2017-09-16T01:43:26+0000","dateStarted":"2017-09-16T01:43:25+0000"},{"text":"val orc = \"s3://vectortiles/orc/europe/finland.orc\"\n//val df = ss.read.orc(\"s3://vectortiles/orc/europe/finland.orc\")\n//val df = ss.read.orc(\"s3://osm-pds/planet/planet-latest.orc\")","dateUpdated":"2017-09-15T22:43:14+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\norc: String = s3://vectortiles/orc/europe/finland.orc\n"}]},"apps":[],"jobName":"paragraph_1505515394783_1343778001","id":"20170912-195450_1591677940","dateCreated":"2017-09-15T22:43:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1284"},{"text":"df\n    .select(\"lat\", \"lon\", \"id\", \"user\", \"uid\", \"changeset\", \"version\", \"timestamp\", \"tags\")\n    .where(\"user = 'lossyrob'\")\n    .count()\n","dateUpdated":"2017-09-15T22:43:14+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nres19: Long = 610\n"}]},"apps":[],"jobName":"paragraph_1505515394784_1329542292","id":"20170912-195924_708474401","dateCreated":"2017-09-15T22:43:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1285"},{"text":"      val layout: LayoutDefinition =\n        ZoomedLayoutScheme.layoutForZoom(14, WebMercator.worldExtent, 512)\n\n\n      osm.fromORC(orc) match {\n        case Left(e) => println(e)\n        case Right((ns,ws,rs)) => {\n          val nodePartitioner = new HashPartitioner(100)\n          val wayPartitioner = new HashPartitioner(100)\n\n          /* Reproject nodes */\n\n          val reprojectedNodes =\n            ns.partitionBy(nodePartitioner).mapPartitions({ partition =>\n              val transform = Proj4Transform(LatLng, WebMercator)            \n              partition.map { case (nodeId, node) =>\n                val (lon, lat) = transform(node.lon, node.lat)\n                (nodeId, node.copy(lon = lon, lat = lat))\n              }\n            }, preservesPartitioning = true)\n\n          /* Assumes that OSM ORC is in LatLng */\n          val feats: RDD[osm.OSMFeature] =\n            osm.toFeatures(reprojectedNodes, ws.partitionBy(wayPartitioner), rs)\n            \n          // feats.count()\n\n          /* Associated each Feature with a SpatialKey */\n          val fgrid: RDD[(SpatialKey, Iterable[osm.OSMFeature])] =\n            VectorPipe.toGrid(Clip.byHybrid, VectorPipe.log4j, layout, feats)\n\n          /* Create the VectorTiles */\n          val tiles: RDD[(SpatialKey, VectorTile)] =\n            VectorPipe.toVectorTile(Collate.withoutMetadata, layout, fgrid)\n            \n          tiles.count()\n        }\n      }\n","dateUpdated":"2017-09-15T22:43:14+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nlayout: geotrellis.spark.tiling.LayoutDefinition = GridExtent(Extent(-2.0037508342789244E7, -2.0037508342789244E7, 2.0037508342789244E7, 2.0037508342789244E7),4.777314267823516,4.777314267823516)\n\nres7: AnyVal = 410952\n"}]},"apps":[],"jobName":"paragraph_1505515394785_1329157543","id":"20170912-200623_759453934","dateCreated":"2017-09-15T22:43:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1286"},{"text":"val n = \n osm.fromORC(orc) match {\n        case Left(e) => println(e); None\n        case Right((ns,ws,rs)) => {\n            Some(ns.first())\n        }\n        \n }","dateUpdated":"2017-09-15T22:43:14+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nn: Option[(Long, vectorpipe.osm.Node)] = Some((115878,Node(66.4971622,25.7304937,ElementData(ElementMeta(115878,BoomEngine,288925,14626250,5,2013-01-12 19:13:09.0,true),Map(),None))))\n"}]},"apps":[],"jobName":"paragraph_1505515394785_1329157543","id":"20170912-205311_1762819321","dateCreated":"2017-09-15T22:43:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1287"},{"text":"// FOR THE WHOLE PLANET\nval df = ss.read.orc(\"s3://osm-pds/planet/planet-latest.orc\")\ndf\n    .select(\"id\")\n    .where(\"type != 'node'\")\n    .count()\n    ","dateUpdated":"2017-09-15T22:43:14+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ndf: org.apache.spark.sql.DataFrame = [id: bigint, type: string ... 10 more fields]\n\nres17: Long = 440490961\n"}]},"apps":[],"jobName":"paragraph_1505515394786_1330311790","id":"20170914-023935_1728759823","dateCreated":"2017-09-15T22:43:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1288"},{"text":"val total = 4502050947L\nval nodes = 4061559986L\nval nonNodes = total - nodes\n(nodes * (8+8)) + (nonNodes * (8 + 16)) // Number of bytes to store the keys of tiles that could intersect geometries","dateUpdated":"2017-09-15T22:43:14+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ntotal: Long = 4502050947\n\nnodes: Long = 4061559986\n\nnonNodes: Long = 440490961\n\nres21: Long = 75556742840\n"}]},"apps":[],"jobName":"paragraph_1505515394787_1329927041","id":"20170914-024600_1268527826","dateCreated":"2017-09-15T22:43:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1289"},{"text":"(nodes * (8+1+8)) + (nonNodes * (8 + 1+16))","dateUpdated":"2017-09-15T22:43:14+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nres20: Long = 80058793787\n"}]},"apps":[],"jobName":"paragraph_1505515394788_1328003296","id":"20170914-025333_182749173","dateCreated":"2017-09-15T22:43:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1290"},{"text":"// FOR FINLAND\nval df = ss.read.orc(\"s3://vectortiles/orc/europe/finland.orc\")\ndf\n  .select(\"id\")\n  .where(\"type = 'node'\")\n  .count()","dateUpdated":"2017-09-15T22:43:14+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ndf: org.apache.spark.sql.DataFrame = [id: bigint, type: string ... 10 more fields]\n\nres9: Long = 33792531\n"}]},"apps":[],"jobName":"paragraph_1505515394789_1327618547","id":"20170914-050605_500171014","dateCreated":"2017-09-15T22:43:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1291"},{"text":"// FOR THE WHOLE PLANET\nval df = ss.read.orc(\"s3://osm-pds/planet/planet-latest.orc\")\n\n//df\n//    .select(\"id\")\n//    .where(\"type != 'node' OR (lon <= -34.767608642578125 AND lon >= -81.33865356445312 AND lat <= 12.623252653219012 AND lat >= -55.98609153380838 AND timestamp <= '2017-06-01 00:00:00.0')\")\n//    .count()","dateUpdated":"2017-09-16T01:43:50+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ndf: org.apache.spark.sql.DataFrame = [id: bigint, type: string ... 10 more fields]\n"}]},"apps":[],"jobName":"paragraph_1505515394789_1327618547","id":"20170914-025645_685582604","dateCreated":"2017-09-15T22:43:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1292","user":"anonymous","dateFinished":"2017-09-16T01:43:55+0000","dateStarted":"2017-09-16T01:43:50+0000"},{"text":"143649996 - 132877507//33792531","dateUpdated":"2017-09-15T22:43:14+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nres15: Int = 10772489\n"}]},"apps":[],"jobName":"paragraph_1505515394790_1328772794","id":"20170914-051234_1690547725","dateCreated":"2017-09-15T22:43:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1293"},{"dateUpdated":"2017-09-16T01:44:08+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1505515394791_1328388045","id":"20170914-052259_138168579","dateCreated":"2017-09-15T22:43:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1294","text":"val southAmerica  = \n  df\n    .where(\"type != 'node' OR (lon <= -34.767608642578125 AND lon >= -81.33865356445312 AND lat <= 12.623252653219012 AND lat >= -55.98609153380838 AND timestamp <= '2017-06-01 00:00:00.0')\")","user":"anonymous","dateFinished":"2017-09-16T01:44:08+0000","dateStarted":"2017-09-16T01:44:08+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nsouthAmerica: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: bigint, type: string ... 10 more fields]\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1505516753563_2007804220","id":"20170915-230553_508932485","dateCreated":"2017-09-15T23:05:53+0000","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2422","text":"      osm.fromDataFrame(southAmerica) match {\n        case Left(e) => println(e)\n        case Right((ns,ws,rs)) => {\n          val nodePartitioner = new HashPartitioner(500)\n          val wayPartitioner = new HashPartitioner(500)\n\n          /* Reproject nodes */\n          val reprojectedNodes =\n            ns.partitionBy(nodePartitioner).mapPartitions({ partition =>\n              val transform = Transform(LatLng, WebMercator)\n              partition.map { case (nodeId, node) =>\n                val (lon, lat) = transform(node.lon, node.lat)\n                (nodeId, node.copy(lon = lon, lat = lat))\n              }\n            }, preservesPartitioning = true)\n\n          /* Assumes that OSM ORC is in LatLng */\n          val feats: RDD[osm.OSMFeature] =\n            osm.toFeatures(reprojectedNodes, ws.partitionBy(wayPartitioner), rs)\n            \n        feats.count()\n        }\n      }\n","dateUpdated":"2017-09-16T01:44:13+0000","dateFinished":"2017-09-16T02:26:38+0000","dateStarted":"2017-09-16T01:44:13+0000","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\norg.apache.spark.SparkException: Job aborted due to stage failure: Task 264 in stage 1.0 failed 4 times, most recent failure: Lost task 264.3 in stage 1.0 (TID 752, ip-172-31-21-172.ec2.internal, executor 32): ExecutorLostFailure (executor 32 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 5.6 GB of 5.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.\nDriver stacktrace:\n  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1569)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1557)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1556)\n  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1556)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:815)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:815)\n  at scala.Option.foreach(Option.scala:257)\n  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:815)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1784)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1739)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1728)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:631)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087)\n  at org.apache.spark.rdd.RDD.count(RDD.scala:1158)\n  ... 66 elided\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1505516843053_714217121","id":"20170915-230723_1619908653","dateCreated":"2017-09-15T23:07:23+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2547","text":"import vectorpipe.osm._\n    val nodes: RDD[(Long, Node)] =\n      southAmerica\n        .select(\"lat\", \"lon\", \"id\", \"user\", \"uid\", \"changeset\", \"version\", \"timestamp\", \"tags\")\n        .where(\"type = 'node'\")\n        .map { row =>\n          val lat: Double = row.getAs[java.math.BigDecimal](\"lat\").doubleValue()\n          val lon: Double = row.getAs[java.math.BigDecimal](\"lon\").doubleValue()\n          val tags: scala.collection.immutable.Map[String, String] =\n            row.getAs[scala.collection.immutable.Map[String, String]](\"tags\")\n        val m =     ElementMeta(\n      row.getAs[Long](\"id\"),\n      row.getAs[String](\"user\"),\n      row.getAs[Long](\"uid\").toString, // TODO Use a `Long` in the datatype instead?\n      row.getAs[Long](\"changeset\"),\n      row.getAs[Long](\"version\"),\n      row.getAs[java.sql.Timestamp](\"timestamp\").toString,\n      true)\n          (lat, lon, m, tags)\n        }\n        .rdd\n        .map({ case (lat, lon, meta, tags) => (meta.id, Node(lat, lon, ElementData(meta, tags, None))) })\nnodes.count()\n","dateUpdated":"2017-09-16T02:30:47+0000","dateFinished":"2017-09-16T02:45:29+0000","dateStarted":"2017-09-16T02:30:47+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport vectorpipe.osm._\n\nnodes: org.apache.spark.rdd.RDD[(Long, vectorpipe.osm.Node)] = MapPartitionsRDD[57] at map at <console>:104\n\nres10: Long = 132773790\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1505528952609_1487691140","id":"20170916-022912_582999227","dateCreated":"2017-09-16T02:29:12+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2967"}],"name":"Working with ORC","id":"2CUHEMCX8","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}